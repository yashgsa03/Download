{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashgsa03/Download/blob/main/RandomForestEEGState.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "5v5PFMUqo3F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install liac-arff\n",
        "!pip install mne # Install the missing mne module"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEzsvsfJCCY3",
        "outputId": "2dff2840-1ab9-4233-caa1-7c28e2b14d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=3930b4e19f01784b50648c41ac4efc74980512983b6ed6a853237ea9cfd5b9f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: liac-arff\n",
            "Successfully installed liac-arff-2.5.0\n",
            "Collecting mne\n",
            "  Downloading mne-1.7.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.6.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert ARFF to CSV"
      ],
      "metadata": {
        "id": "5j-pDW97EEPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import arff\n",
        "import csv\n",
        "\n",
        "with open('./EEG Eye State.arff', 'r') as f:\n",
        "    arff_data = arff.load(f)\n",
        "\n",
        "with open('output.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([attribute[0] for attribute in arff_data['attributes']]) # Access the attributes list using a key\n",
        "    for row in arff_data['data']: # Access the data list using a key\n",
        "        writer.writerow(row)"
      ],
      "metadata": {
        "id": "F3vbIp7aD6ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from mne.preprocessing import ICA # Now you can import ICA from mne\n",
        "import mne\n",
        "\n",
        "# Step 1: Convert .arff to .csv\n",
        "def convert_arff_to_csv(arff_file_path, csv_file_path):\n",
        "    # Try opening the file directly to check if it exists and is accessible\n",
        "    try:\n",
        "        with open(arff_file_path, 'r') as f:\n",
        "            data, meta = arff.loadarff(f)\n",
        "            df = pd.DataFrame(data)\n",
        "            df.to_csv(csv_file_path, index=False)\n",
        "        print(\"Conversion successful!\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {arff_file_path}\")\n",
        "    except PermissionError:\n",
        "        print(f\"Error: Permission denied to access {arff_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# File paths (Update these if necessary)\n",
        "arff_file_path = './EEG Eye State.arff'  # Replace with the correct path\n",
        "csv_file_path = 'output.csv'  # Replace with the desired output path\n",
        "\n",
        "# Convert ARFF to CSV\n",
        "convert_arff_to_csv(arff_file_path, csv_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krvK8_1oECj-",
        "outputId": "3d32e58b-e807-4518-80ce-84b938c131b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Pre-Process CSV File Data"
      ],
      "metadata": {
        "id": "Wl47CtsTEOxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and preprocess data\n",
        "def load_eeg_data(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        print(\"CSV file loaded successfully!\")\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: CSV file not found at {file_path}. Make sure the file exists and the path is correct.\")\n",
        "        return None\n",
        "\n",
        "def bandpass_filter(data, lowcut=0.1, highcut=30, fs=128, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "# Load CSV data\n",
        "raw_data = load_eeg_data(csv_file_path)\n",
        "\n",
        "\n",
        "if raw_data is not None:\n",
        "    # Apply bandpass filter (assuming bandpass_filter is defined elsewhere)\n",
        "    print('......filtering data................')\n",
        "    filtered_data = raw_data.iloc[:, :-1].apply(lambda x: bandpass_filter(x,0.1,30), axis=0)  # Exclude the label column\n",
        "\n",
        "    # ... (Rest of your code)\n",
        "else:\n",
        "    print(\"Error loading data. Further processing is skipped.\")\n",
        "\n",
        "def remove_artifacts_ica(data, sfreq=128, n_components=None): # Set n_components to None\n",
        "    ch_names = [f'EEG {i+1}' for i in range(data.shape[1])]\n",
        "    raw = mne.io.RawArray(data.T, mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg'))\n",
        "    # Determine number of components automatically if not specified\n",
        "    if n_components is None:\n",
        "        n_components = min(data.shape[1], 14) # Set to the number of channels or 14, whichever is smaller\n",
        "    ica = ICA(n_components=n_components, random_state=97, max_iter=800).fit(raw)\n",
        "    return ica.apply(raw).get_data().T\n",
        "\n",
        "# Apply bandpass filter\n",
        "#filtered_data = raw_data.iloc[:, :-1].apply(lambda x: bandpass_filter(x), axis=0)  # Exclude the label column\n",
        "\n",
        "# Remove artifacts using ICA\n",
        "#clean_data = remove_artifacts_ica(filtered_data.values,128,14) # Now this should work without error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTbcDt_9rWPJ",
        "outputId": "66e86d0a-ba8e-4058-889b-a0d9dd03f479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file loaded successfully!\n",
            "......filtering data................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Predict"
      ],
      "metadata": {
        "id": "jz61ukOCEf3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare data for training\n",
        "labels = raw_data.iloc[:, -1]  # Assuming the last column is the label\n",
        "features = pd.DataFrame(filtered_data, columns=raw_data.columns[:-1])\n",
        "\n",
        "# Split and normalize data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train, X_test = sxcaler.transform(X_train), scaler.transform(X_test)\n",
        "\n",
        "# Train\n",
        "# Train and evaluate model\n",
        "clf = RandomForestClassifier(n_estimators=150, random_state=42).fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDU9FHg6EfDU",
        "outputId": "473bc545-effe-4c27-b9e1-b2b9a6edc0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9392523364485982\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        b'0'       0.94      0.94      0.94      1586\n",
            "        b'1'       0.94      0.94      0.94      1410\n",
            "\n",
            "    accuracy                           0.94      2996\n",
            "   macro avg       0.94      0.94      0.94      2996\n",
            "weighted avg       0.94      0.94      0.94      2996\n",
            "\n"
          ]
        }
      ]
    }
  ]
}